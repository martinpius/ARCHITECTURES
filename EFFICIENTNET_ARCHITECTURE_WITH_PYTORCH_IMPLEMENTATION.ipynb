{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EFFICIENTNET-ARCHITECTURE WITH PYTORCH-IMPLEMENTATION ",
      "provenance": [],
      "authorship_tag": "ABX9TyNnvFqNU1fbKpdpe5JSAauU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinpius/ARCHITECTURES/blob/main/EFFICIENTNET_ARCHITECTURE_WITH_PYTORCH_IMPLEMENTATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WheJiz0YrOsv",
        "outputId": "4e344305-1e87-4c3f-8f37-4c641315ddfa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount = True)\n",
        "try:\n",
        "  COLAB = True\n",
        "  import torch\n",
        "  print(f\">>>> You are on CoLaB with torch version: {torch.__version__}\")\n",
        "except Exception as e:\n",
        "  print(f\">>>> {type(e)} {e}\\n>>>> please correct {type(e)} and re-load your drive\")\n",
        "def time_fmt(t: float = 123.87)->float:\n",
        "  h = int(t / (60 * 60))\n",
        "  m = int(t % (60 * 60) / 60)\n",
        "  s = int(t % 60)\n",
        "  return f\"hrs: {h} min: {m:>02} sec: {s:>05.2f}\"\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "print(f\">>>> testing the time formating function...\\n>>>> time elapsed: {time_fmt()}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            ">>>> You are on CoLaB with torch version: 1.9.0+cu102\n",
            ">>>> testing the time formating function...\n",
            ">>>> time elapsed: hrs: 0 min: 02 sec: 03.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGXh-ix31pzB"
      },
      "source": [
        "import torch.nn as nn\n",
        "from math import ceil\n",
        "import time\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQAXVxCQtLaz"
      },
      "source": [
        "#In this notebook we will implement the EfficientNet from scratch:\n",
        "#This network provides an efficient way to optimize any computer vision\n",
        "#network. Using some standardized techniques such as stochastic mini-batches,\n",
        "#Squeeze Excitation and inverted residual blocks. The network can be scaled with\n",
        "# some specified parameters to acquire better performance with less number of parameters"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvXhYzVjwA6B"
      },
      "source": [
        "#information on expansion-ratio, channels, number of layers, stride and kernel size to be used in our base network\n",
        "net_info = [\n",
        "            [1, 16, 1, 1, 3],\n",
        "            [6, 24, 2, 2, 3],\n",
        "            [6, 40, 2, 2, 5],\n",
        "            [6, 80, 3, 2, 3],\n",
        "            [6, 112, 3, 1, 5],\n",
        "            [6, 192, 4, 2, 5],\n",
        "            [6, 320, 1, 1, 3]]\n",
        "\n",
        "#Information on the scale ratio parameters (phi-values, resolution, drop_rate) to be used in our base network\n",
        "scale_info = {\n",
        "    'b0': (0, 224, 0.20),\n",
        "    'b1': (0.5, 240, 0.20),\n",
        "    'b2': (1, 260, 0.30),\n",
        "    'b3': (2, 300, 0.30),\n",
        "    'b4': (3, 300, 0.40),\n",
        "    'b5': (4, 456, 0.40),\n",
        "    'b6': (5, 528, 0.50),\n",
        "    'b7': (6, 600, 0.50),\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKAT8VuD1cdp"
      },
      "source": [
        "#Convilution block..to be used later on in the network\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding, groups = 1):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, \n",
        "                          out_channels,\n",
        "                          kernel_size,\n",
        "                          stride,\n",
        "                          padding, groups = groups, bias = False)\n",
        "    self.bnorm = nn.BatchNorm2d(out_channels)\n",
        "    self.silu = nn.SiLU()\n",
        "  \n",
        "  def forward(self, input_tensor):\n",
        "    return self.silu(self.bnorm(self.conv(input_tensor)))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBREWnxOOSZ1"
      },
      "source": [
        "#A class to compute attention-like scores for each channel:\n",
        "#This class will be used in the inverted-residual block\n",
        "class ChannelAttention(nn.Module):\n",
        "  def __init__(self,in_channels, reduduction):\n",
        "    super(ChannelAttention, self).__init__()\n",
        "    self.atn = nn.Sequential(\n",
        "        nn.AdaptiveAvgPool2d(1), \n",
        "        nn.Conv2d(in_channels,reduction, 1),\n",
        "        nn.SiLU(),\n",
        "        nn.Conv2d(reduction, in_channels, 1),\n",
        "        nn.Sigmoid()) # weight probabilities for each channel\n",
        "  def forward(self, input_tensor):\n",
        "    ''' each input channels is multiplied by the prob weight to\n",
        "    determine their importance to the network'''\n",
        "    x = input_tensor * self.attn(input_tensor)\n",
        "    return x\n",
        "      \n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtvpkWbKSX8I"
      },
      "source": [
        "#The inverted residual network: We utilize the above CNN block here\n",
        "class InvResNet(nn.Module):\n",
        "  def __init__(self, in_channels,\n",
        "               out_channels,\n",
        "               kernel_size, \n",
        "               stride, \n",
        "               padding, \n",
        "               expansion, \n",
        "               reduction = 4, surv_prob = 0.8):\n",
        "    super(InvResNet, self).__init__()\n",
        "    self.surv_prob = 0.8\n",
        "    self.use_residual = in_channels == out_channels and stride==1\n",
        "    hidden_dim = in_channels * expansion #updated dimension (expanded)\n",
        "    self.expand = in_channels != hidden_dim\n",
        "    reduced_dim = int(in_channels / reduction) #reduction factor/ratio\n",
        "    #We now use the convolution blocks we created earlier \n",
        "    if self.expand:\n",
        "      self.expand_cnn = CNN(in_channels, \n",
        "                            out_channels = hidden_dim, \n",
        "                            kernel_size = 3,\n",
        "                            stride = 1, \n",
        "                        padding = 1)\n",
        "    \n",
        "    self.conv = nn.Sequential(\n",
        "        CNN(in_channels = hidden_dim,\n",
        "            out_channels = hidden_dim, \n",
        "            kernel_size = kernel_size,\n",
        "            stride = stride, \n",
        "            padding = padding, \n",
        "            groups = hidden_dim),\n",
        "       ChannelAttention(hidden_dim, reduced_dim),\n",
        "       nn.Conv2d(in_channels = hidden_dim, \n",
        "                 out_channels = out_channels,\n",
        "                 kernel_size = 1, \n",
        "                 bias = False),\n",
        "                 nn.BatchNorm2d(out_channels))\n",
        "  \n",
        "\n",
        "  def stochastic_depth(self, input_tensor):\n",
        "    ''' this will drop some layers randomly during training = layer's dropout'''\n",
        "    if not self.training:\n",
        "      return input_tensor\n",
        "      #generate random binary numbers to decide when we drop a layer during training\n",
        "    binary_v = torch.rand(input_tensor.shape[0], 1, 1, 1, device = device) < self.surv_prob\n",
        "    return torch.div(input_tensor, self.surv_prob) * binary_v\n",
        "  \n",
        "  def forward(self, input_tensor):\n",
        "    x = self.expand_cnn(input_tensor) if self.expand else input_tensor\n",
        "    if self.use_residual:\n",
        "      return self.stochastic_depth(self.conv(input_tensor)) + input_tensor\n",
        "    else:\n",
        "      return self.conv(input_tensor)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5UXK9I_tPxr"
      },
      "source": [
        "#The EfficientNet class: We now develop our model class:"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXZd6QtmuV7G"
      },
      "source": [
        "class EfficientNet(nn.Module):\n",
        "  def __init__(self, version, num_classes):\n",
        "    super(EfficientNet, self).__init__()\n",
        "    w_factor, d_factor, drp_rate = self.compute_factors(version)\n",
        "    final_channel = ceil(1280 * w_factor) #last channel (given in the paper)\n",
        "    self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "    self.features = self.create_features(w_factor, d_factor, final_channel) #creating features\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Dropout(drp_rate),\n",
        "        nn.Linear(final_channel, num_classes))\n",
        "    \n",
        "  \n",
        "  def compute_factors(self, version, alpha = 1.2, beta = 1.1):\n",
        "    '''parameters are provided according to the paper where\n",
        "    alpha == depth-scalling and beta == width-scalling'''\n",
        "    phi, res, drp_rate = scale_info[version]\n",
        "    d_factor = alpha ** phi #how to expand with number of layers\n",
        "    w_factor = beta ** phi # how to expand with number of channels\n",
        "    return d_factor, w_factor, drp_rate\n",
        "  \n",
        "  def create_features(self, w_factor, d_factor, final_channels):\n",
        "    channels = int(32 * w_factor)\n",
        "    features = [CNN(in_channels = 3, out_channels = channels, kernel_size = 3, stride = 2, padding = 1)]\n",
        "    in_channels = channels\n",
        "    for expand_ratio, channels, repeats, stride, kernel_size in net_info:\n",
        "      out_channels = 4* ceil((channels * w_factor) / 4)\n",
        "      layers_rpt = ceil(repeats * w_factor)\n",
        "      #iterate over the repeated layers\n",
        "      for layer in range(layers_rpt):\n",
        "        features.append(InvResNet(in_channels, \n",
        "                                  out_channels,\n",
        "                                  expand_ratio = expand_ratio,\n",
        "                                  stride = stride if layer == 0 else 1,\n",
        "                                  kernel_size = kernel_size,\n",
        "                                  padding = kernel_size//2))\n",
        "        in_channels = out_channels\n",
        "      \n",
        "    features.append(CNN(in_channels, final_channels, kernel_size=1, stride=1, padding=0))\n",
        "    return nn.Sequential(*features)\n",
        "  \n",
        "  def forward(self, input_tensor):\n",
        "    x = self.pool(self.features(input_tensor))\n",
        "    x = x.view(x.shape[0],-1)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "    \n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfCHUDAA6SQU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}